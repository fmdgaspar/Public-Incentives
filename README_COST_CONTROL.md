# ğŸ’° OpenAI Cost Control System

Sistema completo de controlo de custos da API OpenAI com **preÃ§os dinÃ¢micos** e **feedback visual em tempo real**.

## âœ¨ Features

### 1. **PreÃ§os DinÃ¢micos**
- ğŸŒ Taxa de cÃ¢mbio **EUR/USD em tempo real** (API gratuita)
- ğŸ”„ Cache de 12 horas para taxas de cÃ¢mbio
- ğŸ“Š PreÃ§os dos modelos atualizados via web scraping oficial OpenAI
- ğŸ’¾ Cache de 24 horas para preÃ§os dos modelos
- ğŸ›¡ï¸ Fallback automÃ¡tico se APIs falharem

### 2. **Controlo por Request**
- ğŸ’µ Budget mÃ¡ximo por request (default: â‚¬0.30)
- ğŸš« Bloqueio automÃ¡tico de requests que excedam o budget
- âœ‚ï¸ Shrink automÃ¡tico de contexto para caber no budget
- âš–ï¸ CÃ¡lculo preciso com `tiktoken`

### 3. **Cache Inteligente**
- ğŸ’¾ Cache SQLite de todas as respostas
- ğŸ¯ 60-80% de economia esperada
- âš¡ Respostas instantÃ¢neas para prompts repetidos
- ğŸ“ˆ Tracking de hit rate e savings

### 4. **Feedback Visual**
- ğŸ¨ Cores no terminal para fÃ¡cil identificaÃ§Ã£o:
  - âœ… **Verde**: Request barato (<50% do budget)
  - âš ï¸ **Amarelo**: Request moderado (50-80% do budget)
  - ğŸ”´ **Vermelho**: Request caro (>80% do budget)
  - ğŸ’° **Cache hit**: Economia visÃ­vel
- ğŸ“Š Info detalhada: tokens, custo, % do budget, modelo

## ğŸ“– Como Usar

### BÃ¡sico

```python
from backend.app.services.openai_client import ManagedOpenAIClient

# Criar cliente com budget de â‚¬0.30 por request
client = ManagedOpenAIClient(max_per_request_eur=0.30)

# Chat completion
result = client.chat_completion(
    messages=[
        {"role": "user", "content": "Explica eficiÃªncia energÃ©tica"}
    ],
    model="gpt-4o-mini"
)

print(result["response"])
print(f"Custo: â‚¬{result['cost_eur']:.6f}")
print(f"Cache hit: {result['from_cache']}")
```

**Output no terminal:**
```
  âœ… Cost: â‚¬0.000234 (7.8% of â‚¬0.30 budget) | 45 in + 120 out = 165 total tokens | Model: gpt-4o-mini
```

### Embeddings

```python
result = client.create_embedding(
    text="Apoio Ã  eficiÃªncia energÃ©tica para PME"
)

embedding = result["embedding"]  # List[float] com 1536 dimensÃµes
```

### JSON Extraction

```python
result = client.chat_completion(
    messages=[
        {"role": "system", "content": "Extract JSON with fields: name, location"},
        {"role": "user", "content": "Empresa ABC estÃ¡ sediada em Lisboa"}
    ],
    model="gpt-4o-mini",
    response_format={"type": "json_object"}
)

data = result["response_json"]  # Already parsed!
```

### EstatÃ­sticas

```python
stats = client.get_stats()

print(f"Total hoje: â‚¬{stats['total_cost_eur']:.4f}")
print(f"Cache hit rate: {stats['cache']['hits'] / (stats['cache']['hits'] + stats['cache']['misses']) * 100:.1f}%")
```

## ğŸ¯ Exemplo de Output Visual

```bash
# Request normal (barato)
  âœ… Cost: â‚¬0.000123 (4.1% of â‚¬0.30 budget) | 30 in + 50 out = 80 total tokens | Model: gpt-4o-mini

# Request moderado
  âš ï¸ Cost: â‚¬0.000187 (62.3% of â‚¬0.30 budget) | 150 in + 300 out = 450 total tokens | Model: gpt-4o-mini

# Request caro
  ğŸ”´ Cost: â‚¬0.000256 (85.3% of â‚¬0.30 budget) | 500 in + 400 out = 900 total tokens | Model: gpt-4o-mini

# Cache hit
  ğŸ’° CACHE HIT - Saved â‚¬0.000187 | 450 tokens
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Budget

```python
# Budget mais baixo (mais restritivo)
client = ManagedOpenAIClient(max_per_request_eur=0.10)

# Budget mais alto (menos restritivo)
client = ManagedOpenAIClient(max_per_request_eur=0.50)
```

### ForÃ§ar Refresh de PreÃ§os

```python
from backend.app.services.budget_guard import (
    get_gpt4o_mini_prices_cached,
    get_exchange_rate_cached
)

# Refresh exchange rate
rate = get_exchange_rate_cached(force_refresh=True)

# Refresh model prices
prices = get_gpt4o_mini_prices_cached(force_refresh=True)
```

### Tratar Budget Exceeded

```python
from backend.app.services.openai_client import BudgetExceededError

try:
    result = client.chat_completion(messages=[...])
except BudgetExceededError as e:
    print(f"Request too expensive: {e}")
    # Fallback logic here
```

## ğŸ“Š Tabela de PreÃ§os (Exemplo Atual)

Com taxa **1 USD = 0.93 EUR**:

| Modelo | Input (â‚¬/1M tokens) | Output (â‚¬/1M tokens) |
|--------|---------------------|----------------------|
| gpt-4o-mini | â‚¬0.1395 | â‚¬0.558 |
| text-embedding-3-small | â‚¬0.0186 | - |

*PreÃ§os atualizados automaticamente a cada 24h*

## ğŸ¬ Demo Completa

Execute o script de demonstraÃ§Ã£o:

```bash
python examples/demo_cost_tracking.py
```

Demonstra:
1. âœ… Taxa de cÃ¢mbio dinÃ¢mica
2. âœ… Request simples com custo
3. âœ… Cache hits e savings
4. âœ… Warnings para requests caros
5. âœ… Budget enforcement
6. âœ… Embeddings
7. âœ… EstatÃ­sticas diÃ¡rias

## ğŸ§ª Testes

```bash
python examples/test_openai_client.py
```

## ğŸ’¡ Dicas de Economia

1. **Use cache ao mÃ¡ximo**: Requests idÃªnticos sÃ£o grÃ¡tis!
2. **Mantenha prompts concisos**: Menos tokens = menor custo
3. **Use `temperature=0.0`** para comportamento determinÃ­stico (melhor cache hit rate)
4. **Monitore o budget**: Verifique stats regularmente
5. **Batch embeddings**: Processe mÃºltiplos textos de uma vez

## ğŸ” Arquitetura

```
Request
  â†“
Check Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ HIT â†’ Return (â‚¬0)
  â†“ MISS
Get Exchange Rate (cached 12h)
  â†“
Get Model Prices (cached 24h)
  â†“
Check Budget â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ EXCEEDED â†’ Error
  â†“ OK
Estimate Cost
  â†“
Shrink if Needed
  â†“
Call OpenAI API
  â†“
Calculate Actual Cost
  â†“
Save to Cache
  â†“
Track Cost
  â†“
Print Visual Feedback
  â†“
Return Response
```

## ğŸ“ Logs Estruturados

Todos os eventos sÃ£o logged com `structlog`:

```json
{
  "event": "openai_response",
  "timestamp": "2024-10-02T10:30:00Z",
  "model": "gpt-4o-mini",
  "tokens_in": 45,
  "tokens_out": 120,
  "cost_eur": 0.000234,
  "from_cache": false
}
```

## âš¡ Performance

- **Cache hit**: < 1ms
- **Cache miss + API call**: ~500-2000ms
- **Exchange rate fetch**: ~200ms (cached 12h)
- **Price scraping**: ~1000ms (cached 24h)

## ğŸ›¡ï¸ SeguranÃ§a

- âœ… ValidaÃ§Ã£o de inputs
- âœ… Rate limiting via budget
- âœ… Secrets via env vars
- âœ… SQL injection protection (parametrized queries)
- âœ… Fallback em caso de falhas

## ğŸ“š Scripts Ãšteis

```bash
# Extrair AI descriptions de incentivos
python -m backend.app.scripts.extract_ai_descriptions --limit 10

# Gerar embeddings
python -m backend.app.scripts.extract_ai_descriptions --skip-embeddings

# Ver estatÃ­sticas
python -c "from backend.app.services.openai_client import ManagedOpenAIClient; \
  print(ManagedOpenAIClient().get_stats())"
```

## ğŸ“ Conceitos-Chave

### Token
Unidade mÃ­nima de texto (~4 caracteres). "Lisboa" â‰ˆ 2 tokens.

### Cache Hit
Request idÃªntico a um anterior â†’ resposta instantÃ¢nea e grÃ¡tis.

### Budget per Request
Limite mÃ¡ximo de custo para uma Ãºnica chamada Ã  API.

### Shrink
ReduÃ§Ã£o automÃ¡tica do contexto para caber no budget.

---

**Desenvolvido com â¤ï¸ para o AI Challenge | Public Incentives**

